---
title: "Measuring Marginal Effects on Multiple Outcomes"
page-layout: full
editor: source
toc-depth: 5
execute:
  message: false
  warning: false
---

## Set up

This section uses the following packages: 

```{r, include = FALSE}
library(scales)
```

```{r}
library(tidyverse)
library(janitor)
library(skimr)
library(nnet)
library(broom)
library(marginaleffects)
library(gtsummary)
library(ggeffects)
```

We will use the same data as the previous section: 

```{r}
student_survey <- rio::import("/Users/harrietgoers/Downloads/student vote GVPT 729a.dta") |> 
  transmute(warsup = factor(warsup, 
                            levels = c(1, 2, 3, 4),
                            labels = c("Strongly support",
                                       "Somewhat support",
                                       "Somewhat oppose",
                                       "Strongly oppose")), 
            female = factor(female, 
                            levels = c(0, 1), 
                            labels = c("Not female", "Female")), 
            pid = factor(pid,
                         levels = c(1, 2, 3, 4, 5, 6, 7),
                         labels = c("Strong democrat",
                                    "Weak democrat",
                                    "Independent democrat",
                                    "Independent",
                                    "Independent republican",
                                    "Weak republican",
                                    "Strong republican"))) |> 
  labelled::set_variable_labels(warsup = "Support for the war",
                                female = "Female",
                                pid = "Party ID") |> 
  drop_na()

head(student_survey)
```

## Multinomial logit regression

### Interpreting the coefficients

Let's take another look at the model we created previously: 

```{r}
m1 <- multinom(warsup ~ female + pid, data = student_survey)

tbl_regression(m1, intercept = T)
```

We have three options for interpreting coefficients in multinomial logistic regression.

#### Relative log odds

Similar to log odds ratios in binary logistic regression, these can be interpreted as the effect of a one-unit change in $x_i$ on the log odds of being in category 2 compared to being in category 1. 

For example, identifying as female is associated with a `r tidy(m1) |> filter(y.level == "Strongly oppose", term == "femaleFemale") |> pull(estimate) |> round(3)` change in the log odds of strongly opposing compared to strongly supporting the war in Iraq.

This is the default output for our model: 

```{r}
tidy(m1)
```

#### Relative risk ratios

Similar to odds ratios in binary logistic regression, these can be interpreted as the effect of a one-unit change in $x_i$ on the probability of being in category 2 compared to being in category 1. 

For example, identifying as female is associated with a `r tidy(m1, exponentiate = T) |> filter(y.level == "Strongly oppose", term == "femaleFemale") |> pull(estimate) |> percent()` change in the probability of strongly opposing compared to strongly supporting the war in Iraq.

You can get this using `broom::tidy()`:

```{r}
tidy(m1, exponentiate = T)
```

#### Predicted probabilities

This describes the probability that an observation will be in a category for a given a set of observed values. 

For example, the predicted probability that a strong democratic female will strongly support the war in Iraq is `r predict(m1, newdata = tibble(female = factor("Female"), pid = factor("Strong democrat")), type = "probs") |> tidy() |> filter(names == "Strongly support") |> pull(x) |> percent()`. The predicted probability that she will strongly oppose the war is `r predict(m1, newdata = tibble(female = factor("Female"), pid = factor("Strong democrat")), type = "probs") |> tidy() |> filter(names == "Strongly oppose") |> pull(x) |> percent()`.

`broom::augment()` does not currently support multinomial regression. Instead, we can use base R's `predict()`:

```{r}
predict(m1, newdata = tibble(female = factor("Female"), pid = factor("Strong democrat")), type = "probs")
```

We can plot these predicted probabilities across our outcomes and variable options using `ggeffects::ggeffect()`:

```{r}
ggeffect(m1, terms = "female") |> 
  plot()
```

```{r}
ggeffect(m1, terms = "pid") |> 
  plot()
```

## Marginal effects in multinomial logistic regression

We can interpret the marginal effects of a one-unit change in $x_i$ on the change in probability that an observation will fall into one category. 

For example, moving from a strong republican to a strong democrat decreases the probability that an individual will strongly support the war in Iraq by `r marginaleffects(m1, variables = "pid", type = "probs") |> summary() |> filter(group == "Strongly support", contrast == "Strong republican - Strong democrat") |> as_tibble() |> pull(estimate) |> percent()`.

You can calculate the marginal effects of each change using `marginaleffects::marginaleffects()`:

```{r}
marginaleffects::marginaleffects(m1, variables = "pid", type = "probs") |> 
  summary()
```