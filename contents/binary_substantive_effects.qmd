---
title: "Measuring Substantive Effects on Binary Outcomes"
editor: source
toc-depth: 5
execute:
  message: false
  warning: false
---

## Set up

This section uses the following packages: 

```{r, include = FALSE}
library(scales)
```

```{r}
library(tidyverse)
library(rio)
library(skimr)
library(sjPlot)
library(broom)
library(gtsummary)
```

We will use the dataset we set up in the previous section: 

```{r, echo = FALSE}
voters <- rio::import("/Users/harrietgoers/Documents/GVPT729A/class_sets/data/cps00for729a.dta") |> 
  transmute(vote = factor(vote, levels = c(0, 1), labels = c("Did not vote", "Voted")), 
            close, 
            edu7cat = factor(edu7cat), 
            homeown = factor(homeown, levels = c(0, 1), labels = c("Not homeowner", "Homeowner"))) |> 
  labelled::set_variable_labels(vote = "Voted", close = "Registration closing", edu7cat = "Education level", homeown = "Homeownership")

head(voters)
```

```{r, include = FALSE}
# Simulation data used to illustrate theory
df <- tibble(x = runif(1000, 0, 10)) |> 
  mutate(y = if_else(x < 5, 
                     sample(0:1, 1000, replace = T, prob = c(0.95, 0.05)),
                     sample(0:1, 1000, replace = T, prob = c(0.05, 0.95))))
```

## Introduction 

Previously, we explored the effect of a given value of $x_i$ on our expected probability. We are rarely interested in this effect in political science. Rather, we are interested in the effect of a meaningful change in $x_i$ on our expected probability. For example, what is the effect of changing the date of voting registration from 20 days prior to election day to election day? This section will outline how we calculate this **substantive effect** for binary outcomes. 

For non-linear models, we need to specify our values carefully. Unlike linear models, the effect of a one unit change in $x$ on $y$ is not constant. To illustrate, let's look at the effect on the probability of success of moving from $x = 2$ to $x = 3$ compared to the effect of moving from $x = 4$ to $x = 5$: 

```{r, include = FALSE}
m0 <- glm(y ~ x, data = df, family = binomial(link = "logit"))

x_2_pred <- augment(m0, newdata = tibble(x = 2), type.predict = "response") |> pull(.fitted)
x_3_pred <- augment(m0, newdata = tibble(x = 3), type.predict = "response") |> pull(.fitted)
x_4_pred <- augment(m0, newdata = tibble(x = 4), type.predict = "response") |> pull(.fitted)
x_5_pred <- augment(m0, newdata = tibble(x = 5), type.predict = "response") |> pull(.fitted)

```

```{r, echo = FALSE}
ggplot(df, aes(x = x, y = y)) + 
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "glm", se = FALSE, method.args = list(family = binomial(link="logit"))) + 
  geom_vline(xintercept = 2, colour = "lightblue") + 
  geom_hline(yintercept = x_2_pred, colour = "lightblue", size = 1) + 
  geom_vline(xintercept = 3, colour = "darkblue") + 
  geom_hline(yintercept = x_3_pred, colour = "darkblue", size = 1) +
  geom_vline(xintercept = 4, colour = "pink") + 
  geom_hline(yintercept = x_4_pred, colour = "pink", size = 1) +
  geom_vline(xintercept = 5, colour = "red") + 
  geom_hline(yintercept = x_5_pred, colour = "red", size = 1) +
  theme_minimal()
```

Moving from $x = 2$ (highlighted in light blue) to $x = 3$ (highlighted in dark blue) increases the probability of success by `r round(x_3_pred - x_2_pred, 3)`, from `r round(x_2_pred, 3)` to `r round(x_3_pred, 3)`. Moving *the same interval* of one unit from $x = 4$ (highlighted in pink) to $x = 5$ (highlighted in red) increases the probability of success by `r round(x_5_pred - x_4_pred, 3)`, from `r round(x_4_pred, 3)` to `r round(x_5_pred, 3)`. That's a `r round((x_5_pred - x_4_pred) / (x_3_pred - x_2_pred), 3)` times increase in the effect of a one unit change in $x$. 

Therefore, to measure the effect of moving from one value of $x$ to another in a non-linear model, we need to know which values of $x$ we are moving between. This should be theoretically driven: what is an interesting interval for the phenomenon you are measuring? 

## Measuring substantive effects

How do we actually measure the effect of a change from $x_{i1}$ to $x_{i2}$? We predict the estimated probability of success at $x_{i1}$ and at $x_{i2}$ and subtract those probabilities from one another to get the difference. However, there are two factors that complicate this process. First, we need to deal with the other variables in our model: what values should they be held at while we change our variable of interest, $x_i$? Second, how do we measure uncertainty surrounding this estimated effect? We will deal with these challenges in turn. 

### What to do with the other independent variables

There are two dominant approaches to solving this challenge: the average case approach and the observed value approach. 

#### Average case approach

This approach sets all other values to their mean (for continuous variables) or mode (for discrete variables).

1.    Find the mean or mode for all independent variables other than your variable of interest. 

2.    Find your predicted probability of success with your first value of $x_i$, holding all other variables at their mean or mode.

3.    Find your predicted probability of success with your second value of $x_i$, holding all other variables at their mean or mode.

4.    Calculate the difference between these predicted probabilities. 

5.    Discuss the substantive significance of this difference. 

To illustrate, let's explore the predicted effect of changing a state's registration voting date from 20 days prior to election day ($close = 20$) to election day ($close = 0$).

First, let's fit a logistic regression as we did in the previous section: 

```{r}
m1 <- glm(vote ~ close + edu7cat + homeown, data = voters, family = binomial(link = "logit"))

tbl_regression(m1, intercept = T, exponentiate = T)
```

Now, we create a new dataset that contains the values for `close` we want to test and sets the other independent variables to their mean or mode values: 

```{r}
new_data <- tibble(
  close = c(0, 20),
  edu7cat = voters |> count(edu7cat) |> filter(n == max(n)) |> pull(edu7cat),
  homeown = voters |> count(homeown) |> filter(n == max(n)) |> pull(homeown)
)

new_data
```

Next, we calculate the predicted probability that an individual will vote, given these values for our independent variables:

```{r}
result_0_20 <- augment(m1, newdata = new_data, type.predict = "response")
result_0_20
```

Next, we calculate the difference between these predicted probabilities, noting that the only thing that changed in our model is the value of `close`: 

```{r}
result_0_20 <- mutate(result_0_20, diff = (.fitted - lead(.fitted)) * 100)
result_0_20
```

We expect that the probability that an individual will vote increases `r result_0_20 |> filter(close == 0) |> pull(diff) |> round(2)` percentage points when a state's closing date for voter registration moves from 20 days prior to election day to election day. If increasing turnout by `r result_0_20 |> filter(close == 0) |> pull(diff) |> round(2)` percentage points would swing an election in a candidate's favour, this is a substantively significant result.[^1]

[^1]: This is only one interpretation of substantive significance. This should be theoretically (or policy) driven.

However, we have a bit of a problem. Is this really a generalisable result? Haven't we just estimated the effect of this change in registration day closure for a homeowner with an education level of 4? This is the problem with the average case approach: we are discarding an enormous amount of rich data from our sample which is potentially compromising the generalisability of our estimates. In fact, sometimes our average case isn't even in our dataset, which means that we are making out-of-sample predictions.

#### Observed value approach

The observed value approach addresses this issue. It sets all other independent variables to their observed values, only aggregating the estimated effect at the end. 

1.    Find your predicted probability of success with your first value of $x_i$, holding all other variables at their observed values. You will get the same number of predictions as you have observations. 

2.    Find your predicted probability of success with your second value of $x_i$, holding all other variables at their observed values.

3.    Calculate the average predicted probability for each of these values of $x_i$. 

4.    Calculate the difference between these averages. 

5.    Discuss the substantive significance of this difference. 

Let's explore the same question as above to illustrate. 

First, find the predicted probability of an individual voting when $close = 20$: 

```{r}
result_20 <- augment(m1, newdata = mutate(voters, close = 20), type.predict = "response")
result_20
```

Next, find the predicted probability of an individual voting when $close = 0$: 

```{r}
result_0 <- augment(m1, newdata = mutate(voters, close = 0), type.predict = "response")
result_0
```

Next, calculate the average predicted probability for $close = 20$ and $close = 0$:

```{r}
avg_result_20 <- summarise(result_20, avg_20 = mean(.fitted))
avg_result_20
```

```{r}
avg_result_0 <- summarise(result_0, avg_0 = mean(.fitted))
avg_result_0
```

Next, calculate the difference between these averages as a percentage:

```{r}
diff <- (avg_result_0 - avg_result_20) * 100
diff
```

We expect that the probability that an individual will vote increases `r round(diff, 2)` percentage points when a state's closing date for voter registration moves from 20 days prior to election day to election day. If this increase in turnout would swing an election in a candidate's favour, this is a substantively significant result.

#### Which approach should you use?

You should use the observed values approach. Hanmer and Kalkan (2013) demonstrate using simulated data that the observed values approach consistently produces estimates closer to the population's true probability than the average case approach. This makes sense: you are using more data to produce your estimated effects.  